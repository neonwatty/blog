---
title: "Why Nobody On Your Engineering Team Wants to Use Claude Code"
date: "2026-02-05"
excerpt: "The reasons tech teams aren't adopting AI coding tools more rapidly have less to do with the tools and more to do with human nature and broken incentive structures."
tags: ["Claude Code", "AI", "Engineering", "Productivity", "Developer Tools"]
featured: true
author: "Jeremy Watt"
seoTitle: "Why Nobody On Your Engineering Team Wants to Use Claude Code"
metaDescription: "The real barriers to AI coding tool adoption aren't technical — they're management problems, workplace problems, and human nature problems."
---

Most tech teams aren't adopting Claude Code nearly as fast as early adopters like myself expected. The common complaints — it produces slop, it hallucinates, it doesn't understand our codebase — aren't the real reasons. Those are largely solvable as teams learn agentic engineering best practices. The actual barriers are more fundamental — they're management problems, workplace problems, and human nature problems.

---

## Management problems

1. **Incentives.** No carrot, no stick. Engineering leadership is asking developers to 5x their output for the same paycheck and acting surprised when nobody's excited. A handful of people will always be excited to embrace the new and produce more — but they are the exception, not the rule. Why should the rest care? They made an agreement — their time and skill for a salary. They're being asked to radically change how they work and multiply their output, with zero upside for them. Very few people are intrinsically motivated to embrace the new — especially when there's a real learning curve and the reward is the same. Any leader who believes otherwise is either naive or choosing to believe something false about human nature. Teams need actual incentives. Either positive — "deliver 5x and I'll double your comp" — or negative — "adopt this or you're out." Anything in between is leadership pretending that their engineers share their incentives, and they don't.

2. **Leadership.** Leadership is telling engineering teams to adopt these tools but isn't using them themselves. These tools aren't just for writing code — they're useful for product managers, designers, engineering leads, and anyone involved in building software. Instead of leading by example, leadership is often depending on the technical teams to figure these tools out first and spread that knowledge upward and across the organization — which is a difficult ask given the incentive problems in point one. Today it's easier than ever for anyone in product, design, or business to find courses online, watch YouTube tutorials, or simply pick up a tool like Claude itself and learn how to use it for their own use case.

## Workplace problems

1. **Identity.** People are used to doing things their way. They've spent years building workflows, muscle memory, and professional identity around how they work. LLM-driven workflows don't just ask them to learn a new tool — they ask them to fundamentally rethink how they approach their craft. This is hard even for willing people. In past tech shifts, people who weren't interested could quietly sit them out — there was never such an overwhelming signal that a single tool could make them dramatically more productive. And sometimes they were right to, since not every trend panned out. But there hasn't been a gap this large between those who adopted and those who didn't in a very long time.

2. **Curiosity.** Most people in tech companies are not actually that interested in technology. They're doing a job. And very few people, in any industry, are intrinsically motivated to learn new ways of doing that job. This is an uncomfortable truth but it's important to be honest about it.

## Human nature problems

1. **Inertia.** This is a genuinely new kind of technology, and like every major tech shift before it, a large portion of people simply won't adopt it. You know how it feels trying to get someone in your life to use a password manager. You *know* it's better. They *know* it's better. They're never going to do it. This pattern isn't new — some of us spent years trying to get our grandparents to use email, or our parents onto social media, and mostly gave up. Every generation has its version of this. AI coding tools are the latest one. "Using is believing" is real — some people see the power and are immediately hooked — but that's a small minority. Most people are not intrinsically motivated to climb the learning curve, even when the opportunity is massive.

2. **Trust.** LLMs fail in a way no other tool in history fails. A light switch works or it doesn't. A car starts or it doesn't. An LLM works beautifully 99.99% of the time and then confidently hands you something broken or nonsensical. There's a learning curve to working with that — to developing the judgment for when to trust, when to verify, when to course-correct. But nothing in our education system trains people to operate tools that are almost always right and occasionally, unpredictably wrong. We're trained for deterministic systems: follow the steps, get the result. The moment most users hit their first hallucination or weird bug, their trust is broken *permanently*. You will never get them back.
